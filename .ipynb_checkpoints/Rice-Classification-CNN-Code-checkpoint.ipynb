{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17091acf",
   "metadata": {},
   "source": [
    "<a id=\"header\"></a>\n",
    "<center><p style=\"background:#DFDFDF; font-family:Arial; font-weight:bold; font-size:250%; color:black; text-align:center; width:100%; padding:50px\">Rice Classification with CNNs</p></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd6e70e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7e94c30",
   "metadata": {},
   "source": [
    "<a id=\"import\"></a>\n",
    "<center><p style=\"background:#DFDFDF url('pylogo.jpg') no-repeat; font-family:Courier; font-size:200%; color:black; text-align:center; width:80%; padding:30px\">Importing Libraries</p></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c3ff055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Model Building + Training\n",
    "import tensorflow as tf\n",
    "\n",
    "# Clearing Memory\n",
    "from keras.backend import set_session\n",
    "from keras.backend import clear_session\n",
    "from keras.backend import get_session\n",
    "import gc\n",
    "\n",
    "# Operating system\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c7d8edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Keras Session\n",
    "def reset_keras():\n",
    "    sess = get_session()\n",
    "    clear_session()\n",
    "    sess.close()\n",
    "    sess = get_session()\n",
    "\n",
    "    try:\n",
    "        del classifier # this is from global space - change this as you need\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    print(gc.collect()) # if it does something you should see a number as output\n",
    "\n",
    "    # use the same config as you used to create the session\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "    config.gpu_options.visible_device_list = \"0\"\n",
    "    set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0db1aa",
   "metadata": {},
   "source": [
    "<a id=\"import\"></a>\n",
    "<center><p style=\"background:#DFDFDF url('pylogo.jpg') no-repeat; font-family:Courier; font-size:200%; color:black; text-align:center; width:80%; padding:30px\">Train-Val-Test Split</p></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b48f7ac",
   "metadata": {},
   "source": [
    "The split-folders library split folders with files (e.g. images) into train, validation and test (dataset) folders from this format: \n",
    "<pre>\n",
    "\n",
    "input/\n",
    "    class1/\n",
    "        img1.jpg\n",
    "        img2.jpg\n",
    "        ...\n",
    "    class2/\n",
    "        imgWhatever.jpg\n",
    "        ...\n",
    "    ...\n",
    "\n",
    "</pre>\n",
    "\n",
    "Into this format:\n",
    "\n",
    "<pre>\n",
    "\n",
    "output/\n",
    "    train/\n",
    "        class1/\n",
    "            img1.jpg\n",
    "            ...\n",
    "        class2/\n",
    "            imga.jpg\n",
    "            ...\n",
    "    val/\n",
    "        class1/\n",
    "            img2.jpg\n",
    "            ...\n",
    "        class2/\n",
    "            imgb.jpg\n",
    "            ...\n",
    "    test/\n",
    "        class1/\n",
    "            img3.jpg\n",
    "            ...\n",
    "        class2/\n",
    "            imgc.jpg\n",
    "            ...\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fcd1e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust base directory according to your file path\n",
    "base_dir = \"Rice_Image_Dataset\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87c73bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting split-folders\n",
      "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
      "Installing collected packages: split-folders\n",
      "Successfully installed split-folders-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "960885c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "\n",
    "# Splits all images into Train, Test Validation\n",
    "splitfolders.ratio(base_dir, output=\"output\",seed=1337, ratio=(.8, .1, .1), group_prefix=None, move=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4efc8a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train directory:  output\\train\n",
      "Validation directory:  output\\val\n",
      "Test directory:  output\\test\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"output\\\\\"\n",
    "\n",
    "# Setting the directories for our Train, val and test folders\n",
    "train_dir = os.path.join(output_dir, \"train\")\n",
    "print(\"Train directory: \", train_dir)\n",
    "\n",
    "val_dir = os.path.join(output_dir, \"val\")\n",
    "print(\"Validation directory: \", val_dir)\n",
    "\n",
    "test_dir = os.path.join(output_dir, \"test\")\n",
    "print(\"Test directory: \", test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f92379",
   "metadata": {},
   "source": [
    "<a id=\"import\"></a>\n",
    "<center><p style=\"background:#DFDFDF url('pylogo.jpg') no-repeat; font-family:Courier; font-size:200%; color:black; text-align:center; width:80%; padding:30px\">Loading our Data</p></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cb57cc",
   "metadata": {},
   "source": [
    "To load our data, we will be using Tensorflow's ImageDataGenerator. ImageDataGenerator allows to quickly set up Python generators that can automatically turn image files on disk into batches of pre-processed tensors.\n",
    "\n",
    "ImageDataGenerator provides options for adjusting your data, including data augmentation, resizing images, downscaling, and more.\n",
    "\n",
    "Read more [here](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9844bddd",
   "metadata": {},
   "source": [
    "Initially, we will assess the model's performance using our original data, without applying data augmentation. Therefore, our focus will be on downscaling the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfe39054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60000 images belonging to 5 classes.\n",
      "Found 7500 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load 2 instances of ImageDataGenerator. One for our train set, and one for test set\n",
    "# We do not need one for Validation, as it works the same way as our test set\n",
    "train_datagen = ImageDataGenerator(rescale =1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\"\"\"\n",
    "The flow_from_directory function accepts a directory path and generates data batches. \n",
    "It provides options to resize images, specify the color mode, set the class_mode (e.g., binary or categorical), \n",
    "define the batch size, and etc.\n",
    "\n",
    "\"\"\"\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, # Train Directory\n",
    "                                                    target_size=(250, 250), # Image size 250x250px\n",
    "                                                    color_mode='rgb', # 3 channels: R, G, B\n",
    "                                                    class_mode='categorical', # 5 classes, so categorical\n",
    "                                                    batch_size=32) # Set 32 as our batch size\n",
    "\n",
    "# Repeat process for validation set\n",
    "validation_generator = test_datagen.flow_from_directory(val_dir,\n",
    "                                                        target_size=(250, 250), \n",
    "                                                        color_mode='rgb', \n",
    "                                                        class_mode='categorical',\n",
    "                                                        batch_size=32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1302707d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data batch shape: (32, 250, 250, 3)\n",
      "labels batch shape: (32, 5)\n"
     ]
    }
   ],
   "source": [
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2861cce6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
